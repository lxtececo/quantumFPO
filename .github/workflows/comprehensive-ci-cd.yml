name: Comprehensive CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]

env:
  PYTHON_VERSION: '3.13'
  JAVA_VERSION: '21'
  NODE_VERSION: '18'

jobs:
  # Python Backend Tests
  python-tests:
    name: Python Backend Tests
    runs-on: ubuntu-latest
    strategy:
      matrix:
        test-type: [unit, integration, api]

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Cache pip dependencies
      uses: actions/cache@v4
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('backend/src/main/python/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-

    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        cd backend/src/main/python
        if [ -f requirements.txt ]; then
          pip install -r requirements.txt
        fi
        # Install test dependencies
        pip install pytest pytest-cov pytest-mock pytest-asyncio httpx

    - name: Lint Python code
      run: |
        pip install flake8 black isort
        cd backend/src/main/python
        # Check import sorting (non-blocking for now)
        isort --check-only --diff . || echo "Import sorting issues found"
        # Check code formatting (non-blocking for now)  
        black --check --diff . || echo "Code formatting issues found"
        # Lint for critical errors only
        flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
      continue-on-error: true

    - name: Run unit tests
      if: matrix.test-type == 'unit'
      run: |
        cd backend
        python -m pytest src/test/python/test_classic_portfolio_opt.py src/test/python/test_hybrid_portfolio_opt.py -v \
          --tb=short --cov=src/main/python --cov-report=term-missing --cov-report=xml:coverage-unit.xml
      env:
        PYTHONPATH: ${{ github.workspace }}/backend/src/main/python

    - name: Run API tests  
      if: matrix.test-type == 'api'
      run: |
        cd backend
        python -m pytest src/test/python/test_portfolio_api.py -v \
          --tb=short --cov=src/main/python --cov-report=term-missing --cov-report=xml:coverage-api.xml
      env:
        PYTHONPATH: ${{ github.workspace }}/backend/src/main/python

    - name: Run integration tests
      if: matrix.test-type == 'integration'
      run: |
        cd backend
        python -m pytest src/test/python/test_integration_e2e.py -v -m "not slow" \
          --tb=short --cov=src/main/python --cov-report=term-missing --cov-report=xml:coverage-integration.xml
      env:
        PYTHONPATH: ${{ github.workspace }}/backend/src/main/python

    - name: Upload coverage reports
      uses: codecov/codecov-action@v3
      with:
        file: ./backend/coverage-${{ matrix.test-type }}.xml
        flags: python-${{ matrix.test-type }}
        name: python-${{ matrix.test-type }}-coverage
        fail_ci_if_error: false

    - name: Archive test results
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: python-test-results-${{ matrix.test-type }}
        path: |
          backend/coverage-${{ matrix.test-type }}.xml
          backend/.coverage

  # Java Backend Tests
  java-tests:
    name: Java Backend Tests
    runs-on: ubuntu-latest
    strategy:
      matrix:
        test-type: [unit, integration]

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up JDK ${{ env.JAVA_VERSION }}
      uses: actions/setup-java@v4
      with:
        java-version: ${{ env.JAVA_VERSION }}
        distribution: 'temurin'
        cache: maven

    - name: Run unit tests
      if: matrix.test-type == 'unit'
      run: |
        cd backend
        mvn clean test -Dtest="!*Integration*" -B
        mvn jacoco:report

    - name: Run integration tests
      if: matrix.test-type == 'integration' 
      run: |
        cd backend
        mvn clean test -Dtest="*Integration*" -B
        mvn jacoco:report

    - name: Generate test reports
      if: always()
      run: |
        cd backend
        mvn surefire-report:report-only
        mvn site -DgenerateReports=false

    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./backend/target/site/jacoco/jacoco.xml
        flags: java-${{ matrix.test-type }}
        name: java-${{ matrix.test-type }}-coverage
        fail_ci_if_error: false

    - name: Archive test results
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: java-test-results-${{ matrix.test-type }}
        path: |
          backend/target/surefire-reports/
          backend/target/site/jacoco/
          backend/target/site/surefire-report.html

  # Frontend Tests
  frontend-tests:
    name: Frontend Tests
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Node.js ${{ env.NODE_VERSION }}
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
        cache-dependency-path: frontend/package-lock.json

    - name: Install dependencies
      run: |
        cd frontend
        npm ci

    - name: Lint frontend code
      run: |
        cd frontend
        npm run lint
      continue-on-error: true

    - name: Run frontend tests
      run: |
        cd frontend
        npm run test:coverage

    - name: Upload frontend coverage
      uses: codecov/codecov-action@v3
      with:
        file: ./frontend/coverage/lcov.info
        flags: frontend
        name: frontend-coverage
        fail_ci_if_error: false

    - name: Archive frontend test results
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: frontend-test-results
        path: |
          frontend/coverage/
          frontend/test-results.xml

  # Build and Package
  build:
    name: Build Applications
    runs-on: ubuntu-latest
    needs: [python-tests, java-tests, frontend-tests]

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up JDK ${{ env.JAVA_VERSION }}
      uses: actions/setup-java@v4
      with:
        java-version: ${{ env.JAVA_VERSION }}
        distribution: 'temurin'
        cache: maven

    - name: Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Set up Node.js ${{ env.NODE_VERSION }}
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
        cache-dependency-path: frontend/package-lock.json

    - name: Build Java backend
      run: |
        cd backend
        mvn clean package -DskipTests -B

    - name: Package Python backend
      run: |
        cd backend/src/main/python
        pip install -r requirements.txt
        # Verify Python modules can be imported
        python -c "import portfolio_api; print('âœ… portfolio_api module loads successfully')"
        python -c "import classic_portfolio_opt; print('âœ… classic_portfolio_opt module loads successfully')"
        python -c "import hybrid_portfolio_opt; print('âœ… hybrid_portfolio_opt module loads successfully')"
        echo "Python backend modules validated successfully"

    - name: Build frontend
      run: |
        cd frontend
        npm ci
        npm run build

    - name: Archive build artifacts
      uses: actions/upload-artifact@v4
      with:
        name: build-artifacts
        path: |
          backend/target/*.jar
          backend/src/main/python/*.py
          backend/src/main/python/requirements.txt
          frontend/dist/

  # Integration Tests (End-to-End)
  integration-e2e-tests:
    name: End-to-End Integration Tests
    runs-on: ubuntu-latest
    needs: [build]

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Download build artifacts
      uses: actions/download-artifact@v4
      with:
        name: build-artifacts

    - name: Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Set up JDK ${{ env.JAVA_VERSION }}
      uses: actions/setup-java@v4
      with:
        java-version: ${{ env.JAVA_VERSION }}
        distribution: 'temurin'

    - name: Install Python dependencies
      run: |
        cd backend/src/main/python
        pip install -r requirements.txt
        pip install pytest pytest-asyncio requests

    - name: Start Python FastAPI service
      run: |
        cd backend/src/main/python
        python -m uvicorn portfolio_api:app --host 0.0.0.0 --port 8002 &
        echo "PYTHON_API_PID=$!" >> $GITHUB_ENV
        sleep 10  # Wait for service to start

    - name: Wait for Python API to be ready
      run: |
        timeout 30 bash -c 'until curl -s http://localhost:8002/health > /dev/null; do sleep 1; done'

    - name: Run end-to-end integration tests
      run: |
        cd backend
        python -m pytest src/test/python/test_integration_e2e.py -v -m "integration and not slow" --tb=short
      env:
        PYTHONPATH: ${{ github.workspace }}/backend/src/main/python

    - name: Stop Python API service
      if: always()
      run: |
        if [ ! -z "$PYTHON_API_PID" ]; then
          kill $PYTHON_API_PID || true
        fi
        pkill -f "portfolio_api.py" || true

    - name: Archive integration test results
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: e2e-test-results
        path: |
          backend/integration-test-results/

  # Security Scanning
  security:
    name: Security Scanning
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Run Bandit (Python Security)
      run: |
        pip install bandit
        cd backend/src/main/python
        bandit -r . -f json -o bandit-report.json || true
        bandit -r . || true
      continue-on-error: true

    - name: Run Safety (Python Dependency Security)
      run: |
        pip install safety
        cd backend/src/main/python
        safety check -r requirements.txt --json --output safety-report.json || true
        safety check -r requirements.txt || true
      continue-on-error: true

    - name: Run npm audit (Frontend Security)
      run: |
        cd frontend
        npm audit --json > npm-audit.json || true
        npm audit || true
      continue-on-error: true

    - name: Archive security reports
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: security-reports
        path: |
          backend/src/main/python/bandit-report.json
          backend/src/main/python/safety-report.json
          frontend/npm-audit.json

  # Code Quality Gate
  quality-gate:
    name: Quality Gate
    runs-on: ubuntu-latest
    needs: [python-tests, java-tests, frontend-tests, security]
    if: always()

    steps:
    - name: Download all test artifacts
      uses: actions/download-artifact@v4

    - name: Quality Gate Decision
      run: |
        echo "Evaluating quality gate..."
        
        # Check if critical jobs failed
        if [ "${{ needs.python-tests.result }}" = "failure" ]; then
          echo "âŒ Python tests failed"
          exit 1
        fi
        
        if [ "${{ needs.java-tests.result }}" = "failure" ]; then
          echo "âŒ Java tests failed"
          exit 1
        fi
        
        if [ "${{ needs.frontend-tests.result }}" = "failure" ]; then
          echo "âŒ Frontend tests failed"
          exit 1
        fi
        
        echo "âœ… All quality checks passed"

    - name: Generate combined report
      run: |
        echo "# Quality Gate Report" > quality-report.md
        echo "" >> quality-report.md
        echo "## Test Results" >> quality-report.md
        echo "- Python Tests: ${{ needs.python-tests.result }}" >> quality-report.md
        echo "- Java Tests: ${{ needs.java-tests.result }}" >> quality-report.md  
        echo "- Frontend Tests: ${{ needs.frontend-tests.result }}" >> quality-report.md
        echo "- Security Scan: ${{ needs.security.result }}" >> quality-report.md
        echo "" >> quality-report.md
        echo "## Coverage Reports" >> quality-report.md
        echo "Coverage reports are uploaded to Codecov for detailed analysis." >> quality-report.md

    - name: Upload quality report
      uses: actions/upload-artifact@v4
      with:
        name: quality-gate-report
        path: quality-report.md

  # Deploy (conditional on main branch and quality gate pass)
  deploy:
    name: Deploy to Staging
    runs-on: ubuntu-latest
    needs: [build, integration-e2e-tests, quality-gate]
    if: github.ref == 'refs/heads/main' && needs.quality-gate.result == 'success'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Download build artifacts
      uses: actions/download-artifact@v4
      with:
        name: build-artifacts
        
    - name: Deploy to staging
      run: |
        echo "ðŸš€ Deploying to staging environment..."
        echo "This would deploy the built artifacts to a staging environment"
        echo "Available artifacts:"
        find . -name "*.jar" -o -name "*.py" -o -name "dist" | head -10
        
    - name: Run smoke tests
      run: |
        echo "ðŸ§ª Running smoke tests on staging..."
        echo "This would run basic smoke tests against the deployed staging environment"